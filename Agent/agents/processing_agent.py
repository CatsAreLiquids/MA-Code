from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI
from langchain.agents import tool
import os
from dotenv import load_dotenv
import json

from langchain_postgres.vectorstores import PGVector
# import RAG
from langchain_core.prompts import PromptTemplate
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate

from Agent.sharedTool import getCatalogItem
import yaml

load_dotenv()

embeddings = AzureOpenAIEmbeddings(
    model="text-embedding-ada-002",
    azure_endpoint=os.getenv("TextEmb_EndPoint")
)
llm = AzureChatOpenAI(
    azure_endpoint=os.environ["GPT_EndPoint"],
    openai_api_version=os.environ["GPT_APIversion"],
    model=os.environ["GPT_model_name"],
    deployment_name=os.environ["GPT_deployment"],
    temperature=0
)
connection = "postgresql+psycopg://langchain:langchain@localhost:6024/langchain"  # Uses psycopg3!
collection_name = "my_docs"

vector_store = PGVector(
    embeddings=embeddings,
    collection_name=collection_name,
    connection=connection,
    use_jsonb=True,
)



@tool(parse_docstring=True)
def matchFunction(query, catalog_dict,filter_dict):
    """
        Matches a user query to the fitting data product described in the data catalog
        Args:
            query: user query
            catalog_dict: a data catalog item retrieved with getCatalogItem
            filter_dict: extracted attributes and their specific values based on the user query, generated by extractFilter
        Returns:
             a url of a specific dataproduct
    """

    columns = _getProductColumns(catalog_dict['name'])

    # TODO would be really fancy if we can get to a point where stuf like relative growth per 5 year period
    # TODO also stuff  like average per substance is still difficult
    sys_prompt = """ Your task is to identifiy what kind of function a user describes and translate that into a machine readable format
                    Only use values for the column and group by attribute you can find in the column list
                
                    Some examples are:
                    [{{"function":"filter","values":{{"gender":"Female","age":{{"min":38}} }} }},{{"function":"getRows","values":{{"customer_id":"None"}} }}]
                    {{"function":"filter","values":{{"gender":"Female","age":{{"min":38}} }}
                    
                    Possible functions and which values they require are:
                    sum: requires at least one "column" values,which the function is performed on, can have an optional list of "group_by" values
                    mean: requires at least one "column" values,which the function is performed on, can have an optional list of "group_by" values
                    filter: pre filters the data but returns all columns, requires at least on filter attribute based on the filter dict
                    getRows: returns only the specified columns,requires at least one "column" and optionaly specific values 
                """
    input_prompt = PromptTemplate.from_template("""
        User Query:{query}
        available columns:{columns}
        filter_dict: {filter_dict}
    """)
    input_prompt = input_prompt.format(query=query,columns=columns,filter_dict=filter_dict)
    messages = [
        ("system", sys_prompt),
        ("human", input_prompt),
    ]
    return llm.invoke(messages)

def _getProductColumns(file):
    """
        Retrieves columns available in a data product
        file: the file name of a specific data product
        :return: list of all available rows
    """
    # TODO this should be a call to the microservice
    try:
        with open("../dataCatalog/configs/catalog.yml") as stream:
            catalog = yaml.safe_load(stream)
    except FileNotFoundError:
        return "could not find the main catalog"

    for collection in catalog:
        if file in collection['products']:
            try:
                with open("../dataCatalog/configs/" + collection['name'] + ".yml") as stream:
                    collection_dict = yaml.safe_load(stream)
                    for product in collection_dict['products']:
                        if product['name'] == file:
                            return product['columns']

            except FileNotFoundError:
                return "could not find the specific collection catalog"


@tool
def verfiyPlan(dataProduct, plan):
    """
    Verifies that the execution plan and the coressponding data product match, i.e. weather the data referenced in the execution plan is represented in the data product
    dataProduct: name of the data product (retrieved with identifyDataProduct )
    plan: an execution plan created with the createExecutionPlan tool
    :return: bool, description
    """

    cols = _getProductColumns(dataProduct)
    missing_cols = []
    res = True
    msg = "All columns found"

    for elem in plan:
        if plan['elem']  == "filter":
            for key in elem['values'].keys():
                if key not in cols:
                    missing_cols.append(key)

    if missing_cols:
        res = False
        msg = f"could not find the columns {missing_cols}"


    return res,msg

@tool(parse_docstring=True)
def extractFilter(query, catalog_dict):
    """
    Creates a dict including filter atrributes and values for the getDataProduct tool
    Args:
        query: the original user query
        catalog_dict: a dict containing information abpout the data product, can be retrieved with getCatalogItem
    Returns:
         a dict with the corresponding filters such as dict={'Country1':'Austria','Country2':'Germany','min_year':1990,'max_year':1999}
    """
    columns = _getProductColumns(catalog_dict['name'])

    sys_prompt = """Your task is to identify a filterable attribuites in a user query and find how they can be answerd with the data columns present in the data .
                    Only return filters you can find in the data columns
                    Return all filter in a dict 
                    Example 
                    user query : "I would like to have the generall CO2 emissions data of Germany and Austria for the years 2000 to 2010"
                    response: {'Country':['Austria','Germany'],"year":{"min":2000,"max":2010} }
                    user query : "The Co2 data for Aruba where the emissions are between 0.02 and 0.03, from 1990 onward"
                    response: {'Country': 'Aruba', "value":{'min': 0.02, 'max': 0.03} "year":{'min':1990} }
                    user query : "Customer sales data of women over 38 paying by credit card"
                    response: {'gender': 'Women', 'age':{'min':38,'max':38} , 'pyament': "credit card"}
                    user query : "Customers who have not payed with creddit card"
                    response: {'gender': 'Women' , 'pyament': {'not':"credit card"}}
                    """

    input_prompt = PromptTemplate.from_template("""
            User Query:{query}
            available columns:{columns}
            """)
    input_prompt = input_prompt.format(query=query, columns=columns)
    messages = [
        ("system", sys_prompt),
        ("human", input_prompt),
    ]
    return llm.invoke(messages)

def init_agent():
    sys_prompt = """ Your task is to identify and match the necerssary steps and functions to transform a data product based on a users query
                    Use the extractFilter and matchFunction tool !
                    
                    The output should be a string containing a list of valid of python dictionaires, each dict containing one execution step and the necerssary values:
                    User query: "All females customers who paid with Credit Card and are at least 38 years old"
                    response: [{{"function":"filter","values":{{"gender":"Female","age":{{"min":38,"max":38}} }} }},{{"function":"getRows","values":{{"customer_id":"None"}} }}]
                    User query: "Average of cost off all item categorys per shopping mall"
                    response: [{{"function": "mean", "values": {{"column": "price","group_by":["category","shopping_mall"]}} }}]
                    do not return a json, return only the result ith no explanantion
        """
    prompt = ChatPromptTemplate.from_messages(
            [
                ("system",sys_prompt),
                ("human", "{input}"),
                ("placeholder", "{agent_scratchpad}"),
            ]
        )


    tools = [matchFunction, extractFilter, getCatalogItem,verfiyPlan]

    agent = create_tool_calling_agent(llm, tools, prompt)

    return AgentExecutor(agent=agent, tools=tools, verbose=True)


if __name__ == "__main__":
    user = "From the sales data i would like to know the total amount of money spent per category of available items, of women over 38"
    agent = init_agent()
    print(agent.invoke({'input':user})['output'])